# Discord Meeting Transcript â€” March 1, 2026
Duration: ~75 minutes
Transcribed via OpenAI Whisper

--- Segment 1 ---

and like, so call an agent and it returns with an answer. Can you talk to that sub-agent again to clarify or work further? Or does it not? Good question. So in the Arc2 agent, you can see here that the function it had access to is literally this function. So it could pass objects from one repel to the other, but it could only call the agent once, like it wasn't a persistent agent. So these recursive delegation patterns that I showed, like each node here is an agent. The main agent is obviously the central, like the root node, but each agent can only be called once. Difference is that in the Arc3 attempt, what we did is this is the Arc3 agent. So what we did is we actually gave it the spawn agent function. Essentially, how many times each agent was called. So these were persistent. And that's, I think, a better way to go about it. I think in the Arc2 case, like the level of interaction isn't really baked into the game. Whereas like, what I find with Arc3 is that the interactive nature of the game, like the main agent itself is interacting, like it's aware of the fact that it interacts with the game state, it updates. So generally speaking, interacting with an agent seems to be more natural in this setting. Let's say calling it multiple times, or asking it to go away and discover something, get its answer back, then asking it to go away and play, or try a specific level. So in the Arc3 agent, we had like one main agent. Every agent was called with these things in scope. So every agent had the ability to spawn agents. It also had NumPy, and it had this sort of like memories approach, where essentially it had like a shared database of memories that each agent could add memories to, as if like, let's say a sub-agent was discovering something, it could write a memory to this database. And that was shared between agents. And so yeah, in the Arc3 case, they were able to like create agents, and then just use agent.call, the primitive of the SDK, essentially. So the whole agent object, full-time. Does that answer your question? Yeah, yeah, yeah, totally. Got you. Thanks. No worries. Yeah, so maybe this is potentially more interesting to people, which is like the Arc3 agent. So this is kind of how the Arc3 was designed. The three runs actually, where it completed three games, didn't actually include memories yet. This is just a way, this was a way that my colleague came up with to deal with essentially, let's say one sub-agent errors for some reason, or gets slightly starts drifting off into maybe like a bit of context world. You have the ability to essentially like draw out key memories along the way, obviously that's self-initiated by the sub-agent, but the orchestrator agent still has the ability to like retrieve useful information from that trajectory, even if the errors, or if it's slightly sort of starts going a bit awry. So the main things that it had access to in the three runs where it managed to solve all levels, were spawn agent, NumPy, and then essentially you give it the whole game engine. So we give it the game state. So in the Arc3 agents we go, I'm sure a lot of you know this, but generally when you define a custom agent on code, you just do submit action. And instead what we did is just gave it the whole, like the ability to submit multiple actions at a time and just run the game agent outside, obviously of the rubble, but the agent has like full autonomy in terms of how it interacts with that engine. So all updates to the game, obviously done through the official like Arc3 API, but it has this game state object where it can essentially see the last frame of the like game. And it knows how many levels have been computed, how many levels have been like won, and the main agent is basically able to like pass down a sort of a submit action function to sub-agents if it wants to. So this was kind of the setup that we have. And yeah, so these are the runs of the agent. Or it can ask again? Yeah, sure. When, on what level are the actions taken? So like, do the agents come back and then an action, is that a sub-agents come back and then an action is taken on the top level, or do sub-agents call actions? Yeah, sure. So it's only, there's only one game state, right? So it like, it gets passed to the sub-agents. If that makes sense. So then like all cumulative actions are counted, because there's just one, of one game basically. Yeah, but so sub-agents can take actions as well? Yeah, so not by default, one agent has the choice whether or not to pass the submit action function. Don't forget guys, you can put your questions here. And if it does, then sub-agents can take actions. Yeah. Yeah, and then, so like, if you have multiple agents, sub-agents running in parallel, then there would be one agent that, sorry? Yeah. Hold on, does it work? Yeah. So you don't, like, for these runs, we didn't allow multiple sub-agents running in parallel. So we basically asked it to just, like, to sub-agent, and then wait for each side. If you had multiple sub-agents running in parallel, then you would essentially be like. I'll keep an eye on the chat and ask any questions if you may want. And then you'd have to, like, account for that. And you'd still have to, like, sum the committed actions. But you would need to somehow take that in. And I don't think that's really how the, you know, the algorithm works. No, no, no, yeah, it makes sense. Yeah. Thank you. No worries. So yeah, so later on we added memories and we also added something called makeBoundedSubmitActions. This is where the agent is able to, like, pass the submit action function, but it's bounded to a limit of a certain number of actions to a sub-agent. And this really is just, like, to essentially avoid kind of, like, a main agent being like, here's a thousand actions, feel happy, feel, like, very alpha, like that. And yeah, that was quite key. And another thing is that we passed the game reference, which is basically like a small markdown file explaining just, like, the state of how to, not how to play this game, but more just like, you know, almost like a game of non-stop system prompt. We passed that into the agent's record so that then it can pass that to sub-agents. Because remember that sub-agents here are spawned by the agent, the main agent. So the main agent can come up with whatever system prompt it likes. But it should include similar things to the system prompt that it had to replace that as a variable in the record. And it's told, look, if you want to spawn a sub-agent, make sure you basically concatenate onto the end of the game reference when you give it a system prompt. So yeah, this is kind of the setup. We have this frame of glass. Can I have a question regarding, I think you mentioned something about the orchestrator like multiple actions consecutively, right? But do they still keep trying to update their state after a submit action has been done? Or it actually just submits multiple actions in one go? Yeah, the orchestrator literally does like a polling and it does submit action. I mean, the orchestrator barely submits any actions. Majority of the time, the sub-agents are the ones submitting actions. But any agent, if they have that polling, that then iterates and it does submit actions because it knows, let's say, it wants to walk a particular path, then those actions will be submitted consecutively and the state update will come at the end. Does that make sense? Yeah, I see, thank you. Yeah, and the reason I'm asking is because just out of purely token cost-saving, I actually have my loop also submitting multiple actions, but I was always wondering about like, hey, an agent comes up with a plan and then it collects the new information, but didn't have a chance to incorporate those information into the plan, so now it just keeps hitting the wall and wastes nine actions just hitting the wall. So I wonder if your system kind of can account for that anyhow, because I really like the cost-saving. It saves a lot of costs. Whether I don't want to have something to just look at it and interrupt it and force it to run again. Yeah, I think that it's a great point, like to what extent do you encourage kind of like real autonomy and saying, okay, you know the direction you want to go and you have some, I've seen it, we've seen it in timely, it's like, you know, Sources Park algorithms to go and traverse like a round the world or something. It's great to encourage that level of autonomy and just be like, go and execute and submit all these actions in a loop, but it's also very difficult to know when you should show, before like cut off and show the game state to be like reconsider. The answer is, I don't have a good answer to that. I think the majority of the time that right now amounts to good prompting, which is to say carefully consider when you know something like a composite actions should basically be submitted versus when you should incrementally discover. And I think that's like a really important distinction is like a discovery phase versus a, I know exactly how this works phase. And to encourage like the appropriate behavior in each of those phases. Does that make sense? Yeah, that makes total sense. And did you, so did you specifically prompt that to be like initially exploring or the agent kind of decide themselves? That's a good question. Like definitely in the system prompt for the main agent as we say like, you need to figure out how to play this game essentially and like explore the actions, right? Because obviously every game, each of the sort of seven APs have completely different meanings. So that's definitely something that is like encouraged in the initial, if the timeline of the main agent is here in the initial like main agent timeline. And generally what happens is it spawns sub-agents to go and explore. That tends to be like, that sometimes tends to be one of the most, there's two like very action heavy areas. Like the first is the exploration and the second is basically when you get a sub-agent that just gets very stuck at a particular level. And I think that that's something that like is not easy to solve. One thing like I would wanna do is basically, like one that's so to address the first concern, I thought about actually giving it a bounded action tool where it can only, it has a bounded set of possible actions that's smaller than like the total set of actions. Because it might be the case that for example, if a sub-agent spawn, if an agent said, go figure out what this arrow does, go figure out what this key does, that that ends up being slightly less action heavy than it needs to be if like one agent starts sort of composing multiple different actions in a for loop, understanding what moves, what changes. I find that discovery tends to be more token efficient and action efficient when it's basically restricted to like a single discrete action, because it can basically very easily like render a diff on the grid and start to understand. I don't know whether that will generalize to all of the other games that are coming. I played all of the six games that were originally available and I know that sometimes that probably won't work. But yeah, I definitely have been playing around with like a bounded submit action, but not necessarily an integer limit for the number of actions, but actually just the subsets of actions that it's allowed to use. For the second part, which I find to be not so action efficient, which is where a sub-agent sort of goes off on a tangent or find one particular level very difficult. I think that essentially, I think that agents should be encouraged to limit the number of actions sub-agents can use sort of like in a monotonically decreasing fashion with time to like the harder levels. One should have to essentially think more basically, because I think the harder levels are more prone to having these, or at least we've seen these kind of like really long actions on the graphs, these really long plateaus basically. I hope that answers your question. Thank you very much, yeah. I was asking. Yeah, so this is the R3 agent and you can see some runs. Here, these are the three times that are like one for each. There's obviously, I just want to stress there's a new agent for every game. Obviously the same like code, it's a new agent. It's not like one agent is playing all three games. And yeah, so you can essentially see maybe better here. This is, apologies for the log scale on the X-axis. Like imagine this is all much more bunched up, but I was trying to basically, like they were all too squished to left. You can see these really big plateaus, right? For like LS20, the pink line, it happens at level six. And for VC33, it happens at level four, where you get these really long plateaus of like, which always corresponds to basically a sub-agent starting to really misunderstand what is happening at that level and the change from before. And then you get these sort of, if you look at LS20, the pink line, you get these quite nice, like quite reasonable jumps in between levels. And that kind of, you know, to me screams like a bit of a, something to be fixed basically, where you can't really afford to have these in terms of like action efficiency. You can't really afford to have these agents running off. And you can see that also this plateau happens like obviously less dramatically because it's a log scale, but also at the beginning, right? It's kind of like discovery phase. There are a lot more actions. And this is actually the real breakdown. So these are the levels, scores, number of actions, and then the base number of human actions for each game. So for LS20, like it beats some of the, it gets 100% essentially on just under half of the levels. And for VC33 and FT09, it really doesn't. You can see red, these kind of like sub-agents just going off on a tangent. So for example, LS20, 3,240 actions on the last level. Yeah, I was gonna ask what happened there. That last level was, I don't remember it being that hard. Yeah, it got really stuck. I mean, it isn't like if you were a human, but it got really stuck. It just couldn't really, if I go back to the games, like it couldn't really understand what was going on. And this is like in particular, a sub-agent, right? So maybe let's see when the video on the left goes to level seven. The levels don't update. This is a bug in the Arc API, by the way, there's the levels don't update in the right-hand corner. So yeah, this is basically, it's getting through them, it goes through them pretty quickly, the middle ones. And essentially in the last one where there's that shadow almost, it just really can't. I mean, it's playing better than me. Like if I were to go and try it, pick it up, and I played it before, wow. Yeah, this is a nice one, like where it soars through the middle levels, but the last level is almost painful to watch. And I think, yeah, here we go. So I'm pretty sure this is the last level. And it's just really the kind of like, in my mind, this exploration phase now essentially wholly depends on like, you no longer have that exploration phase in the beginning of the level where you see every object. And that massively messes with this previous strategy, which is to map out exactly where everything is. And at this point you have like what, maybe three quarters of a 250,000 context window of the main orchestrated agent constantly being reinforced, this idea that the strategy is working. And it's like, it's something. So it's that fog of war, fog of wars on the last level. That's the only difference, right? In LS20. And it just, it fails to basically massively change the strategy. Interesting. And that's something that's really interesting, I think. If you want to test it, I do have a re-skin of LS20 that is mixed up the levels, different colors, added fog of war from level one. So.


--- Segment 2 ---

I would, uh, I would love to do that. Yeah, I have it. I'll, we can chat after the call, but yeah, and Sanfam also, Sanfam also made a totally different RIF. I don't think it's even a reskin of any of the existing ones, so he's also got one that you can test on later, so. But yeah, no, go on. I'm interested in these failure modes, because you've got such impressive action scores, and then we'll look at, like, VC33 level 5, and it's like, what happened there? I mean, yeah, it's, it's, um, it's pretty difficult. It's, like, uh, I would also say, um, reproducibility is always, it's always difficult. Like, one of the things that pays me the most is that, um, and I do, I do think, like, at least I would love to try this with open source models, because you can basically host them yourself, set a seed, and reproducible, like, reproducibly, reliably reproduce each one. Um, but obviously the problem is with closed source models, like, I really can't, um, and that then becomes pretty difficult to manage. Um, so, yeah, in terms of how, in terms of how to get these down, my colleague Samuel has found that memories, having the shared memories, um, uh, instance can be incredibly useful. Like, the action scores overall, uh, are slightly better, um, but in terms of sub-agents being, going off on one, essentially, um, I think there's more work to be done. It's, at least to me, it might be Tim, it's not obvious immediately how to remedy that. Um, having, being able to sort of check up on sub-agents, I mean, like, a feature of the SDK that, uh, I'm sure lots of us who work on it would, like, really like to add. Um, it's quite difficult to do, uh, but it's not impossible. I was going to ask, like, I mean, I was going to ask because checking up on sub-agents seems to be something that other agents aren't particularly good at. Um, like, and it's interesting if you, if you're struggling with this making the SDK, I mean, I'm wondering what are other people, like, what is Cloud Code doing in its SDK? Because, I mean, Anthropic's got one for agents. How are they solving this? Um, like, what's the baseline that we're all going off of? Because they're essentially state-of-the-art in what agents can do it. Sure. Yeah, I, um, so I use Cloud Code a hell of a lot, and, um, uh, the sub-agents can be run in the background, which is quite nice, and it can continue, um, which is something that I think is very interesting. Uh, for the purpose of, um, these, like, very hierarchical games, I'm not sure how relevant it is, um, to sort of, like, spawn off a bunch of sub-agents, especially when you have action efficiency, sort of breathing down your neck, um, because you really have to be slightly in control of everything. Um, but it also is able to re-query or resume sub-agents, so much like how here we give the ability to call a sub-agent twice. Um, in terms of checking up, it can run tasks on the background and kill, in the background and kill them. Um, I'm not entirely sure to what extent it can actually see the logs. I know that all logs of Cloud Code agents are saved, um, into, like, a docload slash, and then the set, like, the repo, uh, path, and then slash, and then every session ID has logs in it. Um, so it might, it might be able to. There might be some feature I'm missing, but from what I can tell, it could maybe, like, live go and, like, sort of launch a sub-agent in the background and, like, start catting its logs and sort of grepping through them to check if it's doing well, and then maybe go back and cancel the run. I don't know how, uh, how, uh, kosher that is. Or you could do that in Agentica as well. I did, like, briefly suggest it as a crazy idea. Like, you could give the path to the log file where the sub-agent logs are being streamed, you could give that to the main agent, and it could then basically, um, analyze them. But I mean, well, that's, that's, I mean, that's interesting. Isn't that what I'm doing essentially as the, as the human driver to some extent? It's just, I've got a much larger context window than all of my agents do. Yeah, yeah, yeah, that is sort of what you're doing is, like, going through the logs and looking. I find that, yeah, that's a, that's a good way of thinking about it. Um, I think the only difference there is that, like, we have the ability to forget, which is something that never leaves me. Like, it's, like, memory is one thing, but forgetting is another. Like, like, which is really, really important. Like, removing things from the context window is just as much of a, um, of a bonus for agents sometimes as adding things. Um, so that's also sometimes what, what I find interesting about these levels is, like, to what extent would memories help versus hinder in terms of remembering what a strategy from a previous level. Um, and it might not be the case that it's always better to remember exactly what you did on that level or some summarization of how some agent did it on that level. Yeah, I mean, that's, like, that's not actually necessarily the case. Yeah, I mean, as a game designer, that's, like, what we aim for is, you know, like, what helped you on level one is going to kill you on level two or something like that, you know, just to keep it interesting. Um, but it's those kind of, like, mechanics that, like, switch things up on players. Um, and that's one thing I guess we've seen from LLM agents is, like, when something's out of distribution, they're just suddenly like, oh, whoa, wait, there's a bug. They'll tell me, you know, there's a bug in the game. Yeah, no, it's not, it's not me. Yeah, my best, my best guess is that's slightly what happened in, uh, level seven of Alice 19, right? Um, which is just that it was, like, entirely thrown. Um, and I think that, uh, like, understanding that situation better. And my main thing about R2, um, which I've said before is, like, I, I added the sort of RLM recursive language models that are interesting. Like, they are more than spawning sub-agents. They're also not a model architecture. So I'm not really sure about why they're called recursive language models, but you can't train language models to be, like, inherently recursive. Um, but, uh, using, like, closed source, um, with this, like, recursive pattern, um, it's interesting to what extent that actually helps. So I added it when I was running with Opus 4.5, and it increased the score by roughly 5% on the public heap that I fought to. So I sort of thought, okay, great. And I saw that it basically really helped with tasks where the context was just being eaten down. Um, and, uh, that, so I left that in there, but I, I never actually had time to run propagation studies for different models about really the effect of the REPL versus sub-agents. Um, and the other thing about recursive languages, language models, or really, like, the way things are set up in both R2 and R3 in the repos that we've released, is that, like, there's a notion of passing state as, as much as there is passing, like, tasks or string or, like, natural language queries. And that's something that's different, sort of, from traditional sub-agents. Um, it's kind of, uh, asking them, okay, look, I'm going to place, like, a very specific, like, in R2, agents would place specific examples in the REPL of a sub-agent and say, just analyze these examples, or, or maybe place only the challenge and the, like, current Python function and say, just see if this generalizes. Um, and it's basically a way to just, like, it's a way to do sub-agent handoffs that are outside of the context window as much as they are, like, passing the button inside the context window. Um, and I think that's, like, an interesting thing that could possibly be played with, played with, with R3, is a notion of, like, handing down a game state. There's various ways you can do that. Um, and it's not clear to me, like, what the best one is. Um, and also handing down an action space, which I mentioned earlier. Like, do you need all of these actions to figure out how the game works, or can you independently verify how each action works? Um, that's, like, it's the same with memories, right? Handing down memories or giving access to memories. Um, that, that, that, this is all very much like, uh, you know, you try something and then see if it works, basically. So, yeah, I'm conscious that I've spoken for a long time, so I don't want to, like, take up too much time. No, no, I mean, no, this is, this is fascinating. Uh, and we'll even give you a few minutes to, uh, um, promote, uh, Gentica in general. What are you guys using it for? Like, uh, what are you guys, uh, seeing the use cases? I mean, um, you mentioned, you know, you're using cloud code. We're all using cloud code, I think, at this point. Um, uh, so, like, what are, yeah, what are the use cases here? So, so generally it tends to be, uh, like, uh, long context tasks with a lot of data. So search over, like, large document stores, uh, REPL can be incredibly useful for this. Um, basically just storing things as variables. This is kind of like where the original RLM, like, added something that wasn't necessarily, like, didn't need to be recursive, just having state, like, staple variables which hold context. So it's very useful. Agents can sort of, like, project over things. So I, some, like, I do, I've done, like, POCs with some search providers, um, or, like, self-hosting document embedding providers, um, because those agents essentially, uh, can, like, manipulate the data in a much more token-efficient way. Um, the other thing is, uh, heavy data analysis. So, like, the classic SQL data agents, it can be a lot more token-efficient for them to essentially be able to execute commands from a REPL, store, like, particular slices or, like, frame space inside variables in a REPL. So those are, to be honest, the biggest uses that I'm seeing. Um, generally, it has to be quite a context-heavy task. If you're trying to build, like, a Slack bot, um, it's probably not necessary to have a REPL. Um, and I think that, like, there are, uh, many people who are, um, and I'm not in any way going to proclaim that it's more useful to use Jetsica. Um, so I think it really depends on the task, but those are certainly the two tasks that I've seen, um, it be incredibly useful for. Uh, and, yeah, I, I think that one of the nicest things, which I think, like, um, also mentioned in Vivia's, uh, post is that, like, we're seeing an increasing amount of models, uh, increasing number of models, basically, be fine-tuned with interleaved thinking. So this, this ability to reason whilst, like, interleaving is what we're calling, and, um, the REPL is sort of just like a, a version of that, but with, like, some sort of state back behind it and programmatic tool calling. Um, so it'll be interesting, actually, to, I think, discover, uh, good use cases for proper stateful interleaved reasoning. Um, the ones that I work on are mainly, like, long reasoning tasks mixed with data analysis and search and things like that. Okay, very, very interesting. Um, one of the questions from, from the chat was, um, you know, what are some of the different ways that you've considered for handing down game state and action space and memories? And I guess, I mean, one of the interesting things will be, well, what are some of the things you've thought of and haven't worked? So we all know about those. Um. That's a very good question. To be honest, I haven't played around with this enough. Um, uh, like, the game state, I think, like, one of the most important things when testing a new strategy, I, is essentially, like, spending a lot of time, people use the term, the term back pressure in agentic coding, which is basically, like, to what extent the, the tests in, like, let's say your repo, um, uh, can provide sufficient pressure for the agent to, like, I might have misinterpreted this, but this is my interpretation, um, sufficient, like, uh, evidence to basically, like, push the agent in the right direction. Um, but I also kind of, like, uh, it's basically testing and verification and, like, one of the main things that I try to do is just when I, uh, come up with, like, a change, essentially, to the scope or the prompt, um, the first thing I try to do is basically make sure that there's no misunderstanding between what I'm doing, what I think the agent will be able to do and what it can, because that's often, um, the first thing that actually ends up cropping up, and then you can completely dismiss a theory, but you don't actually, you shouldn't have dismissed it, you just weren't trying it properly, um, so I would say, like, tends to be one of the biggest drivers of changing something, it's just when a model clearly wants to do something a certain way and there's some miscommunication between what you think it should be doing and what it wants to do, so generally, I try to pick, like, a path of least resistance, like, the memories, um, objects came from my colleague Samuel, uh, who basically identified this pattern of sub-agents, like, it's just a way to extract information. In terms of handoffs, um, the, like, the grids take up a lot of token space, right, like, a lot of context, sorry, um, and, like, it would be nice to, uh, have maybe a little bit more of a formalized language of, like, diffs or something like that, um, which could be handed down as much as whole grids are, um, or whole frames, I don't know, the problem is that this, like, like, might not actually reduce the size that much, um, I'd love to see more and more usage outside of the context window, like, I would, I would hope that there's also a better way of describing this after actions have been taken, like, in my mind, one of the most, uh, like, it's, like, just the opposite of what, I think someone mentioned earlier, where it's, like, you have an agent running some action in a for loop, when should, like, how can you decide to intercede and be, like, no, look at the game state before you take more actions, it's also, like, the case of the opposite, when it knows exactly what it wants to do, and it shouldn't have any, like, huge grids printed out in between, and, like, passing, passing that knowledge in between sub-agents right now is, like, a little bit maybe not optimal, it still has to print grids, which I find quite difficult to, sort of, get my head over, because, um, one of the biggest things that I found agents, uh, that got stuck and spawned sub-agents in ARC2, one of the biggest helpful things that a sub-agent can do is just phrase the solution in natural language, and then give it back to the agent, and then the agent goes and implements it, and that was, like, a very interesting point for me. That's fascinating, okay, yeah, I'm always interested where, like, natural language is playing a big role in this, that's, okay, go on, I didn't mean to interrupt you, sorry, no, no, you're right, yeah, I wondered to what extent, like, um, not just, like, what should be inside the context window versus as a variable, and then there's somehow some smart way to put that back into the context window, but also how much of a, like, sort of, difference in frame should be a natural language description versus an actual, like, gif of a grid versus just the whole grid again. I think it would have pretty big consequences in terms of, like, switching between natural language descriptions. I can't say either way, though, like, I wouldn't know if it would hurt it or help it. That's fascinating, um, but take another question from the chat, um, uh, we were wondering, have you tried other languages other than Python in the, um, in the, you know, ready val print loop, and are they more efficient, or does that, you know, uh, does the LLM make worse or better code from that? I know I saw that you guys do have a TypeScript SDK, uh, in addition to the Python, so what are your thoughts here, because I have heard that TypeScript is becoming more, you know, more robust in terms of what it can handle with LLMs, but everything is kind of anchored in Python, and I'm not sure, the LLMs, they seem completely fluent in Python, like, to the same extent that I'm fluent in English, because my parents spoke it to me from the day I was born, um, it's like LLMs are the same way, they're just, you know, Python just makes sense to them, um, so I'd be fascinated to hear, you know, what your experience there is. Yeah, so, so, um, initially, like, we actually thought of having the runtime in, in, in TypeScript, but, um, Python just, like, woefully, in some, in some respects, offers a lot more flexibility with respect to types, um, and, uh, I mean, bun just now has a rebel, um, like, I'm sure we're gonna basically, like, put a, put a rebel behind there, I think we'll call him any day, um, and, uh, yeah, we played around with it, I think they're very good at using it, um, in TypeScript, in terms of, I've never implemented it in TypeScript, we have a TypeScript SDK, and we do something which I personally am not a big fan of, um, is, uh, we have a universal message spec for this virtualization protocol, and we essentially have it from Python to Python, but we also have it from TypeScript to Python, allows us to virtualize TypeScript objects in Python, in the Python runtime. In, in my opinion, and it, it, it is a


--- Segment 3 ---

good virtualization of these objects, like it's kind of nuts how it's done but it does actually work quite consistently but the problem for me is that it doesn't really make sense in terms of like agents know there's no Python version of 3.js so like there's a big disconnect there right like in my opinion it should always be the language that's like it's presently coding in and that's like most associated in all of its data it's training data to like those packages so that's a big thing like I think that this was basically for us to like only have one runtime that we would need to like set up and host but I think that that will change like I don't see any reason why LNMs would be completely fine with having a TypeScript repple and I do think it will become more and more important the biggest thing for me that like essentially means that TypeScripts will always be there is that agents becoming like more and more associated with UI interfaces and I think that will change drastically over the next couple of years just like the way we interface with models not necessarily in like a chat functionality and I think that as such like TypeScript will continue to like have to play quite a key role yeah that's yeah that is fascinating but yeah TypeScript is so versatile for things like web interfaces I had my like open claw bots you know I'm like okay you know I don't want you to guys to just write up what you did this week I want you to make a web presentation for me and so you know they're like yeah no problem you know TypeScript sets yeah another question we had from the chat so we've talked about fog of war and that just completely throwing the agent on LS 20 with your understanding of you know current modern agents what kind of games and tasks do you expect them to struggle with besides you know what you've discovered already here or is that just a little mind-blowing still or I mean there's a lot of it I don't think I deeply thought about it but I actually would love to see what happens when you introduce new actions like right now the or at least you change what actions correspond to what like I think one thing I'd love to see be challenged it's like a little bit more of a cutthroat like approach to different levels so the fog of war is I suppose like one instance of that but like a little bit more sort of distinction I would love I would love to see agents like one context window essentially be challenged with like pretty varying tasks because at the moment the way this is done is like for the levels at least it's like subagents really in this approach are taking the front of the head with respect to how to complete this level like how to do some of the action space and I'd love to see what happens when I'm actually potentially not so interested in trying to fit with that in one context but actually trying to fit like can you play three completely different games on agent essentially like I would find that very I mean technically you can always create a new game by just merging two games together because of the level structure of it so like interleaving levels or like that would be pretty interesting to challenge that part I would love to do that I would love skipping levels yes it's good like I think it would be really interesting like for me I don't know I I I would love to see a lot of flexibility as that's sometimes just as useful as I would really like to see that and so another question in regards sorry but another question in regards to the ready Val print loop do you guys make use of a rollback in case like the last couple of steps were just were infeasible or crazy so that the alum can try another approach and like how do you manage that in terms of I mean we've seen like branching I'd be interested to know basically yeah yeah okay um no I haven't actually I think like basically like for the context when they're a certain point and then see how it differs depending like two separate trajectories right and this is kind of like the opposite approach it's not the opposite but it it's maybe like it's essentially sub-agents but with a common history of the main agent and we don't have any rollbacks so this is this is it'd be great we did because essentially like our main agent on level seven of Ellis and you could be like okay I'm stopping you there and I think it would be incredibly useful to do that right now in the SDK we have a local only mode coming soon which is like a much simpler version but right now like you have to have the agents be able to purposely interact or meddle with each other's context windows and the other equivalent thing is like you could just sport a new sub-agent and distill the history from the previous sub-agent if that makes sense you still waste those tokens and those actions in the previous agent but it is a slight version of a rollback it's not the same as a rollback obviously because you don't have that like interleave you know tool result reasoning tool result it would just be like a static prompt from the main agent to the new sub-agent but it would be really interesting to be able to let's say have a main agent was you a sub-agent at a specific point in the context window. Yeah fascinating okay another another question I'm going to keep them coming from the chat how do you experiment and evaluate your agents like what they find actions exploration what we say what we see is the best of 100 runs or how many what is the variance that you observe between runs? So I'm pretty sure that there was there around 15 runs for each of this this is from my from what I got on my colleague Samuel's results I think he did a total of 15 for each of these three ones in terms of how I evaluate my agents 15 runs by the way like like as in launch an agent try to get it to solve all levels what is the variance I can tell you that for arc two variance was pretty minimal between runs probably in the overall public eval score it was probably around one to two percent change that much I I plotted a lot of like histograms with the sort of like you know number of tasks completed I tried to see basically how many would flip interesting that you say how do you evaluate your agents I had like a bit of a meltdown with two because the parser to the way that was designed like it makes sense if you're outputting grids it really doesn't make sense if you're outputting programs because the public eval challenge like one task can have multiple test inputs so then you can get multiple different programs like solving different test inputs and to me the more like the thing I also used to evaluate my agents for up to was actually almost like not a parser to grids but a parser to programs almost where you basically outputted two programs from two separate agents but made a strict condition that all like test inputs tech predicted test outputs for that task had to come from the same one program because to me that was a more interesting metric of like whether or not I was producing programs that generalize well not whether or not I was producing two programs together generalize well and so it's like it like it's an interesting point of how do we evaluate agents and like I think in a blog that I wrote at the bottom I sort of like in the appendix I just like wrote a little note about that because I think it's like to the same perhaps a bit the same here in the sense that like action efficiency is like a very interesting metric to me say it's also important to look at like the distribution of actions as well in terms of you can look at like action efficiency per level you can look at action efficiency overall and then you have to take into account the fact that the levels are supposedly like increasingly harder then that's actually not really what what we necessarily find in terms of the number of actions used per level like for most runs it's difficult to tell whether or not a particular level is going to be harder for an agent so there's definitely variants like there's variants where in some of the runs are free the agents didn't solve all levels it's not as if everyone solved every single level so the three that you see there are the only like sorry the three where we did one and then essentially it's all the levels and then we run out on the second one until it's all to the levels but I think there were no more than 15 runs per each one that's a lot of tokens yeah it's a lot of tokens it's also really it's really heavy that definitely doesn't go unnoticed like it's yeah it's a lot of tokens like I feel bad well no it's interesting because especially when you mentioned you know having the you know we talked about the rollback within within a REPL loop and you know yeah it's a lot of tokens I what I think we're all discovering is that you know there's differing levels of what's a lot of tokens to some people like Peter Steinberger talking about how you know spent $51,000 in API costs like well that's why OpenClob works so well for him it's like you know but uh you know fascinating but you know there's there's going to be so many products and opportunities for things in the realm of token optimization so it's so fascinating because you know the next question coming out is so what are the future research directions that you see what's your 2026 well not just Symbolica but also view yourself what interests you coming up that's fine what about you personally then like kind of I'm interested in seeing how whether like coding agents really slightly stop becoming a little bit more norm core I'd be like I think that already slightly happen with cool co-op and I think it's going to continue to happen in the sense of sort of like coding agents being universal whether or not that be like a nice UI on top of it or not I'm also really interested to see like memory implementations bro I think there are a lot already I'm not really sure where those are gonna go I also am interested in like memory for tool use and I think something like people have focused a lot on at the moment is saving like you know having memory in terms of markdown files which I think is very like very interesting especially for coding agents but I can be very useful but I I particularly am also like very to make executable memory this pertains like mostly to coding agents I mean like a little plug-in that's like basically when cool code agents use clothes water memory they're able to like you know create using the last like X and bash commands that they ran they're able to attach like executables to that memory and so that they then don't have to essentially rewrite all of those scripts fly when they're just running bash commands and like all those kind of optimizations I'm particularly interested in with respect to agents I can't say yeah I've already found something where I've been like okay wow I want to spend you know on this arc free is really interesting I like the way I like the way it's so far and what I've seen not particularly doable in one context I know I think that's quite a good sign in terms of like a test and yeah I did probably round about the sort of things that I'm interested in I think my sound might have just died one last question from the chapter that we had was oh sorry is this about wasn't yes go ahead yeah it's not that big it's quite a nice safety net we have a platform where you can like run agents they passing I do everything locally and on the like the platform you can base it we can pause was and then each agent can basically well you can have multiple agents inside the same micro VM which is quite nice and they sort of aren't interacting with each other the overhead is that if you want to add modules not fun and you have to decide is it a good idea to use a particular module with our PC which in the case of arc very interestingly I tried like virtualizing you have a numpy and that's a terrible idea when you have you know let's say a numpy function being run on every grid of every cell like that actually adds overhead and so yeah I want to basically when I want to add modules it's just it is quite pain I think that's like a big thing I don't it recently released like very sort of like sandbox come on top Monty and you need the first thing everyone was like what about imports and I think that is a really like crucial thing with state for apples but yeah the overhead is mainly just like maybe a long build or longer than it needs to be roughly like 10 minutes which is not that fun but I'm sure it could be optimized and just obviously modules like it's a little bit more of a battle the problem is when it starts affecting an agent experience so like what an agent tries to do and then can't do and that's actually annoying when you're like trying to develop agents and then a technical decision something has like big implications for how an agent forms and that's actually I would say that's like the biggest overhead of compiling to Watson it's like when things start affecting agent performance because of that decision more so than any of that because I like an engineer having to like my bill times that's actually a big interest very interesting and one of the other questions from the chat is about the other the partner templates that are in your docs like you know agent ops hugging face anthropic land chain do you have personal experience with them also ask if you have an ablation study by any chance but I'd be more interested in your personal experience with you know different agent frameworks and everything including like what you're using like as a I'm fascinated to hear that you know people like yourself are even using cloud code and I'm like wow for what so yeah anything you can tell us I'm a big talker user I like a lot I do write plugins just for things that are annoying I'm currently trying to write plugins can you give us an example of a plugin for something that's annoying this is perfect because there's so many people I talk to that don't understand why would I ever want to build a skill why would ever need a plugin so this


--- Segment 4 ---

Perfect. Yes, I made this plugin called Agent Ativan. It's like a fork of this nice repo, which is called Ativan. And it basically allows agents to have this executable memory thing I was talking about earlier. So when agents use Clause, the auto-memory, it can just be like, use this script to run blah. And then instead of it getting saved as a file, because it would often read the file before it runs it. And I don't want it to read the file before it runs it, because it's a file that I know is very specific to this one task that an agent always does in this repo. So I just want it to use the CLI and say dash dash replay, or basically run this file. And if I asked it to save these scripts to files, it would always read it. And that's like token consumption. So I didn't want it to read it. I wanted to just use it. And it knew what the file was trying to do, like what the SQL is for. But it would still read it. So I basically bought this code called Atowin, which is Bash history humans. And I was like, great. This is back now, Bash history for agents. And then I just made a memory crate, which allows agents to just be like agent dash Atowin memory create. And then it can, rather than retyping the commands above, because otherwise, also, if you wanted to save it to a file, it has to retype everything out. So it can just do dash link dash last, and then the last five commands, for example. And then it just saves that as an executable, because the fork of Atowin that I made is just suddenly running in all of the shells of Claude agents and sub-agents. So it's just constantly saving. It has a constant history of every Bash command the agent runs. And so I'm just like, I'm playing on that, basically. That's fascinating. That's a great usage for it. Yeah, that is like, I don't really build. Yeah, I don't really build. I use Claude, the web browser, for documents and stuff. Then, generally, though, I generally use Claude as well for documents, like if I'm writing something. And I need it to be in a specific format or something. I try not to use LMs for writing. But then HuggingFace, I don't know if they do agents. LangChain, I've used before. I'm not a very big fan. It can be really useful for simple agents. But I generally find that there's not many agents that I would want to build that I don't have access to, that I would need to build personally. And also, I suppose I spend quite a lot of time building agents for maybe customers and things like that. So building agents in my free time is, I don't know, I would find it nicer for ARC. Yeah, and I don't have an ablation study with respect to how they perform on ARC, unfortunately. I would really need to dig into that. It would actually be quite a pain to do, because they don't have, it would be a very good setup in the sense of the, I could actually give them a sandbox as a tool where they can run stuff. But it would involve more time. And unfortunately, I don't know if I have the time. Yes, I mean, ARC is an infinite time sink, if you let it be. So I mean, you can go down an infinite rabbit hole with it. So that's interesting, though, that the plugin you built, it was for kind of token optimization, though? You wanted to save your usage? Yeah, I wanted, like, A, I wanted, basically, when I run a lot of evals, it was constantly executing the same bash scripts to check agent logs. But they'd have to be like, it was like a composition of several commands, right? And I wanted to just be like, obviously, write this to a file and then just run it every time. But I also want it to be doing those kind of things, not with me asking. And I also don't want it to have to re-output. When it writes it to a file, I don't want it to have to re-output everything. So the first thing I did was think, OK, I should just be tracking. I need a history, like a SQL database of all these commands or something. And Atowin provides that for humans. It just has a hook that runs to make sure that everything you run is saved, essentially. And then I could start thinking about, what is a useful way for an agent to use this? And the Cloud Code plugin was just like, OK, well, it already has auto-memory features, where it's told to write to a main memory.md. And that's for the whole repo. So if it comes up with good scripts or key points to remember, it should just be attaching the ID for that particular memory, like hash command. And then any other agent knows immediately, because I have hooks that run at the beginning of a session or the beginning of a sub-agent spawn. I have hooks that say, you can replay any memory with this command. And then it essentially can just recall or replay an executable memory, which is attached in the memory file to the memory.md. Interesting. That's fascinating. I just didn't want it to have to keep outputting these scripts, essentially, and never saving them. And they're not even particularly massively useful. They don't need to be checked into the repo or anything. But one thing I'm coming across now is that most of the time, memory.md can be checked into a repo, in which case the whole memory ID doesn't really work, because it doesn't work across machines. So yeah. Yep. We've all kind of let agents into our personal time now with OpenCLAW. So we've all got a lot more experience with that. Have you done that? Do you run an OpenCLAW? Do you have something even more sophisticated? No, I don't, actually. I spend most of my time on my work laptop, and that's definitely forbidden. So I could run it somewhere else. But I haven't actually played around with it. Generally, most of the time, this might sound quite boring, but for now, agents, for me, are mainly to do with not work as in a job, but work, like engineering stuff, not so much my personal life. I get it. I don't know where that OpenCLAW is. OpenCLAW does sound like it can do both, but I need to experiment. Yeah. I get it. I make video games for a living. The last thing I want to do or talk about in my free time is video games. So that's why I'm here talking about agents. But not to take up too much of your personal time with agents, thank you so much for spending what's almost been like an hour and a half with us. I don't know if you can or will. Thank you so much for that. Yeah, no. And I think we managed to get this part of it recorded. So we'll have it, hopefully, for other people to listen to, because I think we had a lot of great insights about agents. So thank you so much for spending your time with us. I have one more slide. Oh. Cook with us. Oh, yes. Yes. Please. We really love to, like, if anyone wants to, like, book this repo and make amendments and et cetera, et cetera, I'm more than happy to, like, talk or, like, work with them or anything. Like, this is very much a, like, open source effort. And, like, you know, ideas are totally welcome. So, yeah, that's me and Samuel, by the way, my colleague. Great, great. Well, thank you so much. We appreciate it. And I know I'll be in touch and probably talk to them later about, we'll give you at least another Arc 3 game to test the SDK on. Oh, thank you so much. Yeah. That'd be great. That'd be great. All right, great. Thanks so much, everybody, also, for coming. Great. And now my dogs are telling me we really need to go outside. They've been very patient. So talk to everybody next week. Have a good one. Thanks for coming. Bye, bye, bye. An indie event. Close stream. Disconnect. All right, OK, we're going. Molly.


