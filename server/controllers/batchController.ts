/**
 * Author: Claude Code using Sonnet 4.5
 * Date: 2025-10-07
 * PURPOSE: Handles batch puzzle analysis with pause/resume/recovery capabilities.
 *          Manages in-memory batch sessions for real-time progress tracking.
 *          Provides resume capability by querying database for existing analyses.
 *
 * SRP and DRY check: Pass - Single responsibility: batch analysis orchestration
 * shadcn/ui: N/A - Backend controller
 */

import { Request, Response } from 'express';
import { logger } from '../utils/logger.ts';
import { formatResponse } from '../utils/responseFormatter.ts';
import { repositoryService } from '../repositories/RepositoryService.ts';
import { puzzleController } from './puzzleController.ts';
import fs from 'fs';
import path from 'path';
import axios from 'axios';

/**
 * Get the internal API base URL for server-to-server calls
 * Uses environment variables to work in both development and production
 */
function getInternalApiBaseUrl(): string {
  const port = process.env.PORT || '5000';
  const host = process.env.INTERNAL_API_HOST || 'localhost';
  return `http://${host}:${port}`;
}

// Types
interface ActivityLogEntry {
  timestamp: Date;
  type: 'info' | 'success' | 'error' | 'warning';
  message: string;
  puzzleId?: string;
}

interface BatchSession {
  id: string;
  modelName: string;
  dataset: string;
  puzzleIds: string[];
  status: 'running' | 'paused' | 'completed' | 'failed';
  progress: {
    total: number;
    completed: number;
    successful: number;
    failed: number;
    percentage: number;
  };
  results: BatchPuzzleResult[];
  activityLog: ActivityLogEntry[];
  startedAt: Date;
  completedAt?: Date;
  currentIndex: number;
  isPaused: boolean;
}

interface BatchPuzzleResult {
  puzzleId: string;
  status: 'pending' | 'analyzing' | 'success' | 'failed' | 'skipped';
  correct?: boolean;
  error?: string;
  processingTimeMs?: number;
  analysisId?: number;
  startedAt?: Date;
  completedAt?: Date;
}

interface BatchStartRequest {
  modelName: string;
  dataset: 'arc1' | 'arc2' | string;
  puzzleIds?: string[];
  resume?: boolean; // Default: true - skip already analyzed puzzles
  promptId?: string; // Default: 'solver'
  temperature?: number; // Default: 0.2
  systemPromptMode?: string; // Default: 'ARC'
}

// In-memory session storage (could be moved to Redis for production)
const activeSessions = new Map<string, BatchSession>();

/**
 * Get all puzzle IDs from a dataset directory
 */
function getPuzzleIdsFromDataset(dataset: 'arc1' | 'arc2'): string[] {
  const dataDir = path.join(process.cwd(), 'data');
  const evalDir = dataset === 'arc1' ? 'evaluation' : 'evaluation2';
  const fullPath = path.join(dataDir, evalDir);

  try {
    const files = fs.readdirSync(fullPath);
    return files
      .filter(file => file.endsWith('.json'))
      .map(file => file.replace('.json', ''));
  } catch (error: unknown) {
    logger.error(`Error reading dataset directory ${fullPath}:`, String(error));
    throw new Error(`Failed to read dataset ${dataset}`);
  }
}

/**
 * Get puzzles that need analysis (resume capability)
 */
async function getPuzzlesNeedingAnalysis(
  allPuzzleIds: string[],
  modelName: string,
  resume: boolean
): Promise<{ toAnalyze: string[], alreadyAnalyzed: string[] }> {
  if (!resume) {
    return { toAnalyze: allPuzzleIds, alreadyAnalyzed: [] };
  }

  const alreadyAnalyzed: string[] = [];
  const toAnalyze: string[] = [];

  // Check each puzzle in the database
  for (const puzzleId of allPuzzleIds) {
    try {
      const explanations = await repositoryService.explanations.getExplanationsForPuzzle(puzzleId);
      const hasAnalysis = explanations.some((exp: any) => exp.modelName === modelName);

      if (hasAnalysis) {
        alreadyAnalyzed.push(puzzleId);
      } else {
        toAnalyze.push(puzzleId);
      }
    } catch (error) {
      // If error querying, assume needs analysis
      toAnalyze.push(puzzleId);
    }
  }

  logger.info(`Resume scan: ${alreadyAnalyzed.length} already analyzed, ${toAnalyze.length} need analysis`);

  return { toAnalyze, alreadyAnalyzed };
}

/**
 * Generate unique session ID
 */
function generateSessionId(): string {
  return `batch-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`;
}

/**
 * Add activity log entry to session
 */
function logActivity(
  session: BatchSession,
  type: 'info' | 'success' | 'error' | 'warning',
  message: string,
  puzzleId?: string
): void {
  session.activityLog.push({
    timestamp: new Date(),
    type,
    message,
    puzzleId
  });

  // Keep only last 200 entries to prevent memory issues
  if (session.activityLog.length > 200) {
    session.activityLog = session.activityLog.slice(-200);
  }
}

/**
 * Analyze a single puzzle using the existing analyze endpoint
 */
async function analyzeSinglePuzzle(
  puzzleId: string,
  modelName: string,
  options: {
    promptId?: string;
    temperature?: number;
    systemPromptMode?: string;
  }
): Promise<{ success: boolean; correct?: boolean; error?: string; analysisId?: number }> {
  try {
    // Get internal API base URL once (environment-aware)
    const baseUrl = getInternalApiBaseUrl();
    
    const requestBody = {
      temperature: options.temperature ?? 0.2,
      promptId: options.promptId ?? 'solver',
      systemPromptMode: options.systemPromptMode ?? 'ARC',
      omitAnswer: true,
      retryMode: false
    };

    // Use internal API call
    const encodedModelKey = encodeURIComponent(modelName);
    const apiUrl = `${baseUrl}/api/puzzle/analyze/${puzzleId}/${encodedModelKey}`;

    const analysisResponse = await axios.post(apiUrl, requestBody, {
      timeout: 10 * 60 * 1000, // 10 minutes
      headers: { 'Content-Type': 'application/json' }
    });

    if (!analysisResponse.data.success) {
      throw new Error(analysisResponse.data.message || 'Analysis failed');
    }

    const analysisData = analysisResponse.data.data;

    // Save to database
    const explanationToSave = {
      [modelName]: {
        ...analysisData,
        modelKey: modelName
      }
    };

    const saveResponse = await axios.post(
      `${baseUrl}/api/puzzle/save-explained/${puzzleId}`,
      { explanations: explanationToSave },
      { timeout: 30000, headers: { 'Content-Type': 'application/json' } }
    );

    if (!saveResponse.data.success) {
      throw new Error('Save failed');
    }

    // Determine correctness
    const correct = analysisData.isPredictionCorrect ||
                   analysisData.multiTestAllCorrect ||
                   false;

    return {
      success: true,
      correct,
      analysisId: saveResponse.data.data?.id
    };

  } catch (error: any) {
    logger.error(`Failed to analyze puzzle ${puzzleId}:`, error);
    return {
      success: false,
      error: error.response?.data?.message || error.message || 'Unknown error'
    };
  }
}

/**
 * Process batch analysis queue with PARALLEL processing
 *
 * Author: Claude Code using Sonnet 4.5
 * Date: 2025-10-07
 * PURPOSE: Process multiple puzzles concurrently instead of sequentially (10-20x faster)
 * Pattern: Trigger all analyses with staggered delays, then await Promise.all()
 * SRP/DRY check: Pass - Reuses existing analyzeSinglePuzzle and logging infrastructure
 */
async function processBatchQueue(sessionId: string, options: BatchStartRequest): Promise<void> {
  const session = activeSessions.get(sessionId);
  if (!session) {
    logger.error(`Session ${sessionId} not found`);
    return;
  }

  logger.info(`Starting PARALLEL batch processing for session ${sessionId}`);

  // Process remaining puzzles in batches of 10 for manageable concurrency
  const BATCH_SIZE = 10;
  const STAGGER_DELAY_MS = 2000; // 2 second delay between triggers

  while (session.currentIndex < session.puzzleIds.length && !session.isPaused) {
    const batchStartIndex = session.currentIndex;
    const batchEndIndex = Math.min(batchStartIndex + BATCH_SIZE, session.puzzleIds.length);
    const batchPuzzleIds = session.puzzleIds.slice(batchStartIndex, batchEndIndex);

    logger.info(`[Batch ${sessionId}] Processing puzzles ${batchStartIndex + 1}-${batchEndIndex} of ${session.puzzleIds.length}`);
    logActivity(session, 'info', `üöÄ Starting batch of ${batchPuzzleIds.length} puzzles (${batchStartIndex + 1}-${batchEndIndex}/${session.puzzleIds.length})`);

    // Trigger all analyses in this batch concurrently
    const analysisPromises: Promise<{
      puzzleId: string;
      resultIndex: number;
      startTime: number;
      result: any;
    }>[] = [];

    for (let i = 0; i < batchPuzzleIds.length; i++) {
      const puzzleId = batchPuzzleIds[i];
      const resultIndex = batchStartIndex + i;

      // Update status to analyzing
      session.results[resultIndex].status = 'analyzing';
      session.results[resultIndex].startedAt = new Date();

      // Log activity: Starting analysis
      logActivity(session, 'info', `‚ö° Analyzing puzzle: ${puzzleId}`, puzzleId);

      // Trigger analysis (don't await - let it run in parallel)
      const startTime = Date.now();
      const analysisPromise = analyzeSinglePuzzle(puzzleId, session.modelName, {
        promptId: options.promptId,
        temperature: options.temperature,
        systemPromptMode: options.systemPromptMode
      }).then(result => ({
        puzzleId,
        resultIndex,
        startTime,
        result
      }));

      analysisPromises.push(analysisPromise);

      // Stagger requests to avoid API rate limits (except for last puzzle)
      if (i < batchPuzzleIds.length - 1 && !session.isPaused) {
        await new Promise(resolve => setTimeout(resolve, STAGGER_DELAY_MS));
      }
    }

    // Wait for all analyses in this batch to complete
    logger.info(`[Batch ${sessionId}] All ${batchPuzzleIds.length} analyses triggered. Waiting for completion...`);
    const batchResults = await Promise.all(analysisPromises);

    // Process results
    for (const { puzzleId, resultIndex, startTime, result } of batchResults) {
      const endTime = Date.now();
      const timeSeconds = Math.round((endTime - startTime) / 1000);

      // Update result
      session.results[resultIndex] = {
        ...session.results[resultIndex],
        status: result.success ? 'success' : 'failed',
        correct: result.correct,
        error: result.error,
        processingTimeMs: endTime - startTime,
        analysisId: result.analysisId,
        completedAt: new Date()
      };

      // Log activity: Result with validation
      if (result.success) {
        const validationIcon = result.correct ? '‚úì' : '‚úó';
        const validationText = result.correct ? 'CORRECT' : 'INCORRECT';
        logActivity(
          session,
          'success',
          `${validationIcon} ${puzzleId}: ${validationText} (${timeSeconds}s)`,
          puzzleId
        );
      } else {
        logActivity(
          session,
          'error',
          `‚ùå ${puzzleId}: FAILED - ${result.error || 'Unknown error'} (${timeSeconds}s)`,
          puzzleId
        );
      }

      // Update progress
      session.progress.completed++;
      if (result.success) {
        session.progress.successful++;
      } else {
        session.progress.failed++;
      }
    }

    // Update overall percentage
    session.progress.percentage = Math.round((session.progress.completed / session.progress.total) * 100);

    // Move index to next batch
    session.currentIndex = batchEndIndex;

    logger.info(`[Batch ${sessionId}] Completed ${session.progress.completed}/${session.progress.total} puzzles (${session.progress.percentage}%)`);
  }

  // Mark as completed if done
  if (session.currentIndex >= session.puzzleIds.length) {
    session.status = 'completed';
    session.completedAt = new Date();
    logActivity(session, 'success', `‚úÖ Batch analysis completed - ${session.progress.successful}/${session.progress.total} successful`);
    logger.info(`Batch session ${sessionId} completed`);
  }
}

/**
 * Start a new batch analysis session
 */
export async function startBatch(req: Request, res: Response): Promise<void> {
  try {
    const {
      modelName,
      dataset,
      puzzleIds: customPuzzleIds,
      resume = true,
      promptId = 'solver',
      temperature = 0.2,
      systemPromptMode = 'ARC'
    } = req.body as BatchStartRequest;

    if (!modelName) {
      res.status(400).json(formatResponse.error('VALIDATION_ERROR', 'Model name is required'));
      return;
    }

    // Get puzzle IDs
    let allPuzzleIds: string[];
    if (customPuzzleIds && customPuzzleIds.length > 0) {
      allPuzzleIds = customPuzzleIds;
    } else if (dataset === 'arc1' || dataset === 'arc2') {
      allPuzzleIds = getPuzzleIdsFromDataset(dataset);
    } else {
      res.status(400).json(formatResponse.error('VALIDATION_ERROR', 'Invalid dataset or puzzle IDs'));
      return;
    }

    // Apply resume logic
    const { toAnalyze, alreadyAnalyzed } = await getPuzzlesNeedingAnalysis(
      allPuzzleIds,
      modelName,
      resume
    );

    if (toAnalyze.length === 0) {
      res.status(200).json(formatResponse.success({
        message: 'All puzzles already analyzed',
        alreadyAnalyzed: alreadyAnalyzed.length
      }, 'No puzzles need analysis'));
      return;
    }

    // Create session
    const sessionId = generateSessionId();
    const session: BatchSession = {
      id: sessionId,
      modelName,
      dataset,
      puzzleIds: toAnalyze,
      status: 'running',
      progress: {
        total: toAnalyze.length,
        completed: 0,
        successful: 0,
        failed: 0,
        percentage: 0
      },
      results: toAnalyze.map(puzzleId => ({
        puzzleId,
        status: 'pending'
      })),
      activityLog: [],
      startedAt: new Date(),
      currentIndex: 0,
      isPaused: false
    };

    // Log session startup
    logActivity(session, 'info', `üöÄ Starting batch analysis`);
    logActivity(session, 'info', `Model: ${modelName}`);
    logActivity(session, 'info', `Dataset: ${dataset} (${allPuzzleIds.length} puzzles)`);
    if (resume && alreadyAnalyzed.length > 0) {
      logActivity(session, 'info', `Resume mode: Skipping ${alreadyAnalyzed.length} already analyzed`);
    }
    logActivity(session, 'info', `Queue: ${toAnalyze.length} puzzles to analyze`);

    // Mark already analyzed puzzles as skipped in results (for reference)
    const skippedResults: BatchPuzzleResult[] = alreadyAnalyzed.map(puzzleId => ({
      puzzleId,
      status: 'skipped'
    }));

    activeSessions.set(sessionId, session);

    // Start processing in background
    processBatchQueue(sessionId, {
      modelName,
      dataset,
      promptId,
      temperature,
      systemPromptMode
    } as BatchStartRequest).catch(error => {
      logger.error(`Batch processing error for session ${sessionId}:`, error);
      session.status = 'failed';
    });

    res.status(200).json(formatResponse.success({
      sessionId,
      totalPuzzles: allPuzzleIds.length,
      toAnalyze: toAnalyze.length,
      alreadyAnalyzed: alreadyAnalyzed.length,
      skippedPuzzles: skippedResults,
      status: 'running'
    }, 'Batch analysis started'));

  } catch (error: any) {
    logger.error('Error starting batch analysis:', error);
    res.status(500).json(formatResponse.error('BATCH_START_ERROR', error.message));
  }
}

/**
 * Get batch session status
 */
export async function getBatchStatus(req: Request, res: Response): Promise<void> {
  try {
    const { sessionId } = req.params;
    const session = activeSessions.get(sessionId);

    if (!session) {
      res.status(404).json(formatResponse.error('NOT_FOUND', 'Session not found'));
      return;
    }

    res.status(200).json(formatResponse.success({
      sessionId: session.id,
      modelName: session.modelName,
      dataset: session.dataset,
      status: session.status,
      progress: session.progress,
      results: session.results,
      activityLog: session.activityLog,
      startedAt: session.startedAt,
      completedAt: session.completedAt,
      isPaused: session.isPaused
    }, 'Session status retrieved'));

  } catch (error: any) {
    logger.error('Error getting batch status:', error);
    res.status(500).json(formatResponse.error('BATCH_STATUS_ERROR', error.message));
  }
}

/**
 * Pause batch session
 */
export async function pauseBatch(req: Request, res: Response): Promise<void> {
  try {
    const { sessionId } = req.params;
    const session = activeSessions.get(sessionId);

    if (!session) {
      res.status(404).json(formatResponse.error('NOT_FOUND', 'Session not found'));
      return;
    }

    session.isPaused = true;
    session.status = 'paused';

    logActivity(session, 'warning', `‚è∏Ô∏è  Batch analysis paused at ${session.progress.completed}/${session.progress.total}`);

    res.status(200).json(formatResponse.success({
      sessionId,
      status: 'paused'
    }, 'Batch analysis paused'));

  } catch (error: any) {
    logger.error('Error pausing batch:', error);
    res.status(500).json(formatResponse.error('BATCH_PAUSE_ERROR', error.message));
  }
}

/**
 * Resume batch session
 */
export async function resumeBatch(req: Request, res: Response): Promise<void> {
  try {
    const { sessionId } = req.params;
    const session = activeSessions.get(sessionId);

    if (!session) {
      res.status(404).json(formatResponse.error('NOT_FOUND', 'Session not found'));
      return;
    }

    if (!session.isPaused) {
      res.status(400).json(formatResponse.error('INVALID_STATE', 'Session is not paused'));
      return;
    }

    session.isPaused = false;
    session.status = 'running';

    logActivity(session, 'info', `‚ñ∂Ô∏è  Batch analysis resumed from ${session.progress.completed}/${session.progress.total}`);

    // Resume processing
    const options: BatchStartRequest = {
      modelName: session.modelName,
      dataset: session.dataset,
      promptId: 'solver', // Default from initial request
      temperature: 0.2,
      systemPromptMode: 'ARC'
    };

    processBatchQueue(sessionId, options).catch(error => {
      logger.error(`Batch processing error after resume for session ${sessionId}:`, error);
      session.status = 'failed';
    });

    res.status(200).json(formatResponse.success({
      sessionId,
      status: 'running'
    }, 'Batch analysis resumed'));

  } catch (error: any) {
    logger.error('Error resuming batch:', error);
    res.status(500).json(formatResponse.error('BATCH_RESUME_ERROR', error.message));
  }
}

/**
 * Get batch results
 */
export async function getBatchResults(req: Request, res: Response): Promise<void> {
  try {
    const { sessionId } = req.params;
    const session = activeSessions.get(sessionId);

    if (!session) {
      res.status(404).json(formatResponse.error('NOT_FOUND', 'Session not found'));
      return;
    }

    // Filter results to show meaningful data
    const results = session.results.map(result => ({
      puzzleId: result.puzzleId,
      status: result.status,
      correct: result.correct,
      error: result.error,
      processingTimeMs: result.processingTimeMs,
      analysisId: result.analysisId
    }));

    res.status(200).json(formatResponse.success({
      sessionId,
      modelName: session.modelName,
      dataset: session.dataset,
      progress: session.progress,
      results,
      startedAt: session.startedAt,
      completedAt: session.completedAt
    }, 'Batch results retrieved'));

  } catch (error: any) {
    logger.error('Error getting batch results:', error);
    res.status(500).json(formatResponse.error('BATCH_RESULTS_ERROR', error.message));
  }
}

/**
 * List all active sessions
 */
export async function listSessions(req: Request, res: Response): Promise<void> {
  try {
    const sessions = Array.from(activeSessions.values()).map(session => ({
      sessionId: session.id,
      modelName: session.modelName,
      dataset: session.dataset,
      status: session.status,
      progress: session.progress,
      startedAt: session.startedAt,
      completedAt: session.completedAt
    }));

    res.status(200).json(formatResponse.success(sessions, 'Sessions retrieved'));

  } catch (error: any) {
    logger.error('Error listing sessions:', error);
    res.status(500).json(formatResponse.error('BATCH_LIST_ERROR', error.message));
  }
}

export const batchController = {
  startBatch,
  getBatchStatus,
  pauseBatch,
  resumeBatch,
  getBatchResults,
  listSessions
};
