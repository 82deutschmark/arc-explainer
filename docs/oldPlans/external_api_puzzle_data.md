# How to Retrieve All Data for a Specific Puzzle

This document outlines the process for an external application to query the Arc-Explainer API and retrieve all available information for a specific puzzle, using its unique ID.

**ðŸ”„ Recent API Changes:**
- September 15, 2025: API result limits have been significantly increased for external applications
- September 30, 2025: Added debate and rebuttal tracking endpoints

**Example Puzzle ID:** `e7dd8335`

To get a complete picture of a puzzle, you will need to make multiple API calls to different endpoints. Each endpoint provides a specific slice of the data associated with the puzzle.

---

## 1. Core Puzzle Data

This is the primary endpoint to get the fundamental puzzle data, including the training and test grids.

*   **Endpoint:** `GET /api/puzzle/task/:taskId`
*   **Description:** Retrieves the core task data for a single puzzle.
*   **Returns:** A JSON object containing the puzzle's `train` and `test` arrays, which define the input/output grids.

**Example Request:**
```
GET /api/puzzle/task/e7dd8335
```

---

## 2. AI-Generated Explanations

This endpoint retrieves all explanations that have been generated by various AI models for the puzzle.

*   **Endpoint:** `GET /api/puzzle/:puzzleId/explanations`
*   **Description:** Retrieves an array of all explanation records stored for the specified puzzle ID.
*   **Returns:** A JSON array where each object is a detailed explanation, including the model used, the predicted output, confidence scores, pattern descriptions, and more.

**Example Request:**
```
GET /api/puzzle/e7dd8335/explanations
```

---

## 3. User Feedback

This endpoint provides all user-submitted feedback associated with the puzzle's explanations.

*   **Endpoint:** `GET /api/puzzle/:puzzleId/feedback`
*   **Description:** Retrieves all feedback records linked to a specific puzzle ID.
*   **Returns:** A JSON array of feedback objects. This includes votes (`helpful` or `not_helpful`) and textual comments.

**Example Request:**
```
GET /api/puzzle/e7dd8335/feedback
```

---

## 4. User-Submitted Solutions

This endpoint retrieves alternative solutions or explanations submitted by users.

*   **Endpoint:** `GET /api/puzzles/:puzzleId/solutions`
*   **Description:** Retrieves a list of user-submitted solutions for the puzzle.
*   **Returns:** A JSON array where each object represents a user's explanation or solution, including any votes it has received.

**Example Request:**
```
GET /api/puzzles/e7dd8335/solutions
```

---

## 5. Debate & Rebuttal Chain Data âœ¨ NEW! (September 2025)

These endpoints retrieve AI-vs-AI debate information for explanations, showing which models challenged which explanations.

### 5a. Get Rebuttal Chain for an Explanation

*   **Endpoint:** `GET /api/explanations/:id/chain`
*   **Description:** Retrieves the complete debate chain for an explanation, showing all rebuttals in chronological order.
*   **Returns:** A JSON array of explanation objects, ordered from original explanation through all subsequent rebuttals.

**Example Request:**
```
GET /api/explanations/123/chain
```

**Example Response:**
```json
{
  "success": true,
  "data": [
    { "id": 100, "modelName": "gpt-4o", "rebuttingExplanationId": null, "isPredictionCorrect": false },
    { "id": 101, "modelName": "claude-3.5-sonnet", "rebuttingExplanationId": 100, "isPredictionCorrect": false },
    { "id": 102, "modelName": "gemini-2.5-pro", "rebuttingExplanationId": 101, "isPredictionCorrect": true }
  ]
}
```

### 5b. Get Original Explanation Being Challenged

*   **Endpoint:** `GET /api/explanations/:id/original`
*   **Description:** For a rebuttal explanation, retrieves the parent explanation it is challenging.
*   **Returns:** A single explanation object, or 404 if not a rebuttal.

**Example Request:**
```
GET /api/explanations/101/original
```

### 5c. Filter Explanations by Correctness (for Debate)

*   **Endpoint:** `GET /api/puzzle/:puzzleId/explanations?correctness=incorrect`
*   **Description:** Retrieve only incorrect explanations for a puzzle (used for debate challenges).
*   **Query Parameters:**
    - `correctness=correct` - Only correct predictions
    - `correctness=incorrect` - Only incorrect predictions (includes null/unvalidated)
    - `correctness=all` - All explanations (default)

**Example Request:**
```
GET /api/puzzle/e7dd8335/explanations?correctness=incorrect
```

---

## Summary of Process

To aggregate all data for puzzle `e7dd8335`, an external application should:

1.  Call `GET /api/puzzle/task/e7dd8335` to get the base puzzle definition.
2.  Call `GET /api/puzzle/e7dd8335/explanations` to get all AI analyses.
3.  Call `GET /api/puzzle/e7dd8335/feedback` to get all user feedback on those analyses.
4.  Call `GET /api/puzzles/e7dd8335/solutions` to get community-provided solutions.
5.  For debate data:
    - Call `GET /api/puzzle/e7dd8335/explanations?correctness=incorrect` to get debatable explanations.
    - Call `GET /api/explanations/:id/chain` for any explanation to see its debate chain.
    - Call `GET /api/explanations/:id/original` to navigate from rebuttal back to parent.
